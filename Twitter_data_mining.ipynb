{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a688528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "from tqdm.notebook import tqdm\n",
    "from knockknock import slack_sender\n",
    "import os\n",
    "\n",
    "webhook_url = os.environ['KNOCKKNOCK_WEBHOOK']\n",
    "external_storage_path = os.environ['DATASET_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "395ae1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_twitter_single_search(bank, search_term, start_date, end_date):\n",
    "    # pytz to localize the date\n",
    "    utc=pytz.UTC\n",
    "    \n",
    "    # Converting start_date and end_date to datetime objects\n",
    "    start_date = utc.localize(datetime.strptime(start_date, \"%Y-%m-%d\"))\n",
    "    end_date = utc.localize(datetime.strptime(end_date, \"%Y-%m-%d\"))\n",
    "\n",
    "    # Creating list to append tweet data to\n",
    "    tweets_list = []\n",
    "\n",
    "    # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'{search_term} since:{start_date:%Y-%m-%d} until:{end_date:%Y-%m-%d} lang:en').get_items()):\n",
    "        \n",
    "        # Checking if tweet date is before start_date \n",
    "        if tweet.date < start_date:\n",
    "            break\n",
    "\n",
    "        tweets_list.append([tweet.date, tweet.id, tweet.rawContent, tweet.user.username, tweet.replyCount, tweet.retweetCount, tweet.likeCount])\n",
    "\n",
    "    # Creating a dataframe from the tweets list above\n",
    "    tweets_df = pd.DataFrame(tweets_list, columns=['Datetime', 'Tweet_Id', 'Tweet', 'Username', 'Reply_Count', 'Retweet_Count', 'Like_Count'])\n",
    "    \n",
    "    # Adding Bank column to the dataframe\n",
    "    tweets_df[\"Bank\"] = bank\n",
    "    \n",
    "    return tweets_df\n",
    "\n",
    "@slack_sender(webhook_url=webhook_url, channel=\"#general\")\n",
    "def scrap_twitter_multiple_search(bank_dict, start_date, end_date):\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    # Loop through banks\n",
    "    for bank in tqdm(bank_dict.keys(), total=len(bank_dict)):\n",
    " \n",
    "        # Loop through each search term per bank\n",
    "        for search_term in tqdm(bank_dict[bank], total=len(bank_dict[bank])):\n",
    "            dfs.append(scrap_twitter_single_search(bank, search_term, start_date, end_date))\n",
    "\n",
    "    # Concatenate multiple dataframes and drop duplicate tweets\n",
    "    result = pd.concat(dfs).drop_duplicates()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5593247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdac665d8fe9461890dc948624850caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a64f513fea4255b22311bc071ddfc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb4e2187afc49239cd42e98b9fbbb28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3462f16560144538bf496b2990e49db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da7bdd232474a4bb73d06903757e5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0159a2d9530c4eeea1e2b992f71235ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df = scrap_twitter_multiple_search(bank_dict, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8864af0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet_Id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Username</th>\n",
       "      <th>Reply_Count</th>\n",
       "      <th>Retweet_Count</th>\n",
       "      <th>Like_Count</th>\n",
       "      <th>Bank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-12-30 22:54:54+00:00</td>\n",
       "      <td>20613831155785728</td>\n",
       "      <td>RT @RosesR_Red: RT @DAY_BOOGIE: U.N.I.T.Y ( Da...</td>\n",
       "      <td>DAY_STAY_FNB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-12-30 22:51:13+00:00</td>\n",
       "      <td>20612902956306432</td>\n",
       "      <td>U.N.I.T.Y</td>\n",
       "      <td>DAY_STAY_FNB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-12-30 22:13:44+00:00</td>\n",
       "      <td>20603469635256320</td>\n",
       "      <td>@20Ls_January6th so save me some</td>\n",
       "      <td>DAY_STAY_FNB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-12-30 21:30:31+00:00</td>\n",
       "      <td>20592592139853825</td>\n",
       "      <td>RT @20Ls_January6th: Bout Too Makee ShrimpFRiE...</td>\n",
       "      <td>DAY_STAY_FNB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-12-30 21:25:10+00:00</td>\n",
       "      <td>20591248762998784</td>\n",
       "      <td>@fnb_Saturn let's go the week of myy birthday ...</td>\n",
       "      <td>_dannnr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fnb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime           Tweet_Id  \\\n",
       "0 2010-12-30 22:54:54+00:00  20613831155785728   \n",
       "1 2010-12-30 22:51:13+00:00  20612902956306432   \n",
       "2 2010-12-30 22:13:44+00:00  20603469635256320   \n",
       "3 2010-12-30 21:30:31+00:00  20592592139853825   \n",
       "4 2010-12-30 21:25:10+00:00  20591248762998784   \n",
       "\n",
       "                                               Tweet      Username  \\\n",
       "0  RT @RosesR_Red: RT @DAY_BOOGIE: U.N.I.T.Y ( Da...  DAY_STAY_FNB   \n",
       "1                                          U.N.I.T.Y  DAY_STAY_FNB   \n",
       "2                   @20Ls_January6th so save me some  DAY_STAY_FNB   \n",
       "3  RT @20Ls_January6th: Bout Too Makee ShrimpFRiE...  DAY_STAY_FNB   \n",
       "4  @fnb_Saturn let's go the week of myy birthday ...       _dannnr   \n",
       "\n",
       "  Reply_Count Retweet_Count Like_Count Bank  \n",
       "0           0             0          0  fnb  \n",
       "1           0             0          0  fnb  \n",
       "2           0             0          0  fnb  \n",
       "3           0             0          0  fnb  \n",
       "4           0             0          0  fnb  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect tweets and order by the most liked tweets\n",
    "df.head(5).sort_values(by='Like_Count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081c4ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 75037 entries, 0 to 1\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   Datetime       75037 non-null  datetime64[ns, UTC]\n",
      " 1   Tweet_Id       75037 non-null  object             \n",
      " 2   Tweet          75037 non-null  object             \n",
      " 3   Username       75037 non-null  object             \n",
      " 4   Reply_Count    75037 non-null  object             \n",
      " 5   Retweet_Count  75037 non-null  object             \n",
      " 6   Like_Count     75037 non-null  object             \n",
      " 7   Bank           75037 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), object(7)\n",
      "memory usage: 5.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check current dtypes of the columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2032c117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datetime         datetime64[ns, UTC]\n",
       "Tweet_Id                       int64\n",
       "Tweet                         string\n",
       "Username                      string\n",
       "Reply_Count                    int64\n",
       "Retweet_Count                  int64\n",
       "Like_Count                     int64\n",
       "Bank                          string\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set dtypes of columns of dataframe\n",
    "df = df.astype({'Tweet_Id': int, 'Tweet':'string', 'Username': 'string', 'Reply_Count':int, 'Retweet_Count':int, 'Like_Count':int, 'Bank':'string'})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188f4518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 75037 entries, 0 to 1\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   Datetime       75037 non-null  datetime64[ns, UTC]\n",
      " 1   Tweet_Id       75037 non-null  int64              \n",
      " 2   Tweet          75037 non-null  string             \n",
      " 3   Username       75037 non-null  string             \n",
      " 4   Reply_Count    75037 non-null  int64              \n",
      " 5   Retweet_Count  75037 non-null  int64              \n",
      " 6   Like_Count     75037 non-null  int64              \n",
      " 7   Bank           75037 non-null  string             \n",
      "dtypes: datetime64[ns, UTC](1), int64(4), string(3)\n",
      "memory usage: 5.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Check updated column dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eef72ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tweets to parquet form. Note, parquet is a faster and more efficient form of stores larger files compared to csv.\n",
    "df.to_parquet(f\"tweets_from_{start_date}_to_{end_date}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b915322b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-01-01 00:00:00+00:00 2022-12-31 00:00:00+00:00\n",
      "2011-01-01 00:00:00+00:00 2011-12-31 00:00:00+00:00\n",
      "2011-01-01 00:00:00+00:00 2011-12-31 00:00:00+00:00\n",
      "2012-01-01 05:45:36+00:00 2012-12-30 05:45:36+00:00\n",
      "2012-12-31 11:31:12+00:00 2013-12-30 11:31:12+00:00\n",
      "2013-12-31 17:16:48+00:00 2014-12-30 17:16:48+00:00\n",
      "2014-12-31 23:02:24+00:00 2015-12-30 23:02:24+00:00\n",
      "2016-01-01 04:48:00+00:00 2016-12-30 04:48:00+00:00\n",
      "2016-12-31 10:33:36+00:00 2017-12-30 10:33:36+00:00\n",
      "2017-12-31 16:19:12+00:00 2018-12-30 16:19:12+00:00\n",
      "2018-12-31 22:04:48+00:00 2019-12-30 22:04:48+00:00\n",
      "2020-01-01 03:50:24+00:00 2020-12-30 03:50:24+00:00\n",
      "2020-12-31 09:36:00+00:00 2021-12-30 09:36:00+00:00\n",
      "2021-12-31 15:21:36+00:00 2022-12-30 15:21:36+00:00\n"
     ]
    }
   ],
   "source": [
    "# start_year = '2011'\n",
    "# end_year = '2022'\n",
    "\n",
    "# bank_dict = {'fnb': ['fnb', 'FNBSA', 'fnbSouthAfrica'],\n",
    "#              'absa': ['absa', 'absaSA', 'ABSASouthAfrica'],\n",
    "#              'nedbank': ['nedbank', 'NEDBANKSA', 'nedbankSouthAfrica'],\n",
    "#              'capitec': ['capitec', 'CapitecBank', 'capitecSA'],\n",
    "#              'standard_bank': ['standard bank','standardbank', 'StandardbankSA']}\n",
    "\n",
    "\n",
    "\n",
    "# # pytz to localize the date\n",
    "# utc=pytz.UTC\n",
    "\n",
    "# start_date = f'{start_year}-01-01'\n",
    "# end_date = f'{end_year}-12-31'\n",
    "\n",
    "\n",
    "# # Converting start_date and end_date to datetime objects\n",
    "# start_date = utc.localize(datetime.strptime(start_date, \"%Y-%m-%d\"))\n",
    "# end_date = utc.localize(datetime.strptime(end_date, \"%Y-%m-%d\"))\n",
    "\n",
    "# select_start_date = start_date\n",
    "# select_end_date = utc.localize(datetime(start_date.year, 12, 31))\n",
    "# while select_start_date.year < end_date.year:\n",
    "#     print(select_start_date, select_end_date)\n",
    "#     select_start_date += timedelta(days=365.24)\n",
    "#     select_end_date += timedelta(days=365.24)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b72d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
