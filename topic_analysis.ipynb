{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "787eaf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from utilities import clean_tweet\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import tweetnlp\n",
    "from textblob import TextBlob\n",
    "\n",
    "def get_pred(model, tweet):\n",
    "    ouput = model.predict(tweet)\n",
    "    return ouput['label'] \n",
    "\n",
    "def get_sentiment(tweet):\n",
    "    # check polarity of tweet and return sentiment\n",
    "    analysis = TextBlob(tweet)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "def get_polarity(tweet):\n",
    "    return TextBlob(tweet).sentiment.polarity\n",
    "\n",
    "# Load models from tweetnlp\n",
    "# model_hate_speech = tweetnlp.load_model('hate')\n",
    "# model_offensive_language = tweetnlp.load_model('offensive')\n",
    "model_sentiment = tweetnlp.load_model('sentiment')\n",
    "# model_topic = tweetnlp.load_model('topic_classification', multi_label=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b52453d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all parquet files from Tweets folder and concatenate them all into one dataframe\n",
    "df = pd.concat([pd.read_parquet(f) for f in glob.glob('Tweets/*.parquet')], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "993485eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592410f002314ac8a44287d7bc29601e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4469911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1e4af151ef4bada5141a2e8c90c2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4469911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Tweet_Clean'] = df['Tweet'].progress_apply(lambda x: clean_tweet(x))\n",
    "df['Topic'] = df['Tweet_Clean'].progress_apply(lambda x: get_pred(model_topic, x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25b9113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cda3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('topic.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94712701",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(\"I hate you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3b3fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60df5597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.3\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[20:32:28] ../src/common/io.cc:102: Opening test_model.json failed: No such file or directory\nStack trace:\n  [bt] (0) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x18313d) [0x7f2a2c26313d]\n  [bt] (1) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x18372a) [0x7f2a2c26372a]\n  [bt] (2) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x133470) [0x7f2a2c213470]\n  [bt] (3) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterLoadModel+0x187) [0x7f2a2c2137e7]\n  [bt] (4) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/lib-dynload/../../libffi.so.8(+0xa052) [0x7f2c881dc052]\n  [bt] (5) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/lib-dynload/../../libffi.so.8(+0x88cd) [0x7f2c881da8cd]\n  [bt] (6) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x91e7) [0x7f2c881ec1e7]\n  [bt] (7) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x869b) [0x7f2c881eb69b]\n  [bt] (8) /home/nblomerus/anaconda3/envs/nlp2/bin/python(_PyObject_MakeTpCall+0x25b) [0x4f886b]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(xgb\u001b[39m.\u001b[39m__version__)\n\u001b[1;32m      4\u001b[0m booster \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mBooster()\n\u001b[0;32m----> 5\u001b[0m booster\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39mtest_model.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mModels/sentiment/pipemodel_model.pickle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m     clf \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp2/lib/python3.10/site-packages/xgboost/core.py:2441\u001b[0m, in \u001b[0;36mBooster.load_model\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, (\u001b[39mstr\u001b[39m, os\u001b[39m.\u001b[39mPathLike)):\n\u001b[1;32m   2438\u001b[0m     \u001b[39m# assume file name, cannot use os.path.exist to check, file can be\u001b[39;00m\n\u001b[1;32m   2439\u001b[0m     \u001b[39m# from URL.\u001b[39;00m\n\u001b[1;32m   2440\u001b[0m     fname \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(fname))\n\u001b[0;32m-> 2441\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterLoadModel(\n\u001b[1;32m   2442\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, c_str(fname)))\n\u001b[1;32m   2443\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mbytearray\u001b[39m):\n\u001b[1;32m   2444\u001b[0m     buf \u001b[39m=\u001b[39m fname\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp2/lib/python3.10/site-packages/xgboost/core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \n\u001b[1;32m    270\u001b[0m \u001b[39mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39m    return value from API calls\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[39mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[39m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [20:32:28] ../src/common/io.cc:102: Opening test_model.json failed: No such file or directory\nStack trace:\n  [bt] (0) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x18313d) [0x7f2a2c26313d]\n  [bt] (1) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x18372a) [0x7f2a2c26372a]\n  [bt] (2) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x133470) [0x7f2a2c213470]\n  [bt] (3) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterLoadModel+0x187) [0x7f2a2c2137e7]\n  [bt] (4) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/lib-dynload/../../libffi.so.8(+0xa052) [0x7f2c881dc052]\n  [bt] (5) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/lib-dynload/../../libffi.so.8(+0x88cd) [0x7f2c881da8cd]\n  [bt] (6) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x91e7) [0x7f2c881ec1e7]\n  [bt] (7) /home/nblomerus/anaconda3/envs/nlp2/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0x869b) [0x7f2c881eb69b]\n  [bt] (8) /home/nblomerus/anaconda3/envs/nlp2/bin/python(_PyObject_MakeTpCall+0x25b) [0x4f886b]\n\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pickle\n",
    "print(xgb.__version__)\n",
    "booster = xgb.Booster()\n",
    "# booster.load_model('test_model.json')\n",
    "\n",
    "with open('Models/sentiment/pipemodel_model.pickle', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "\n",
    "# loaded_model = pickle.load(open('Models/sentiment/pipemodel_model.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd6ca812",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Classifier.predict() missing 1 required positional argument: 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_sentiment\u001b[39m.\u001b[39;49msentiment()\n",
      "\u001b[0;31mTypeError\u001b[0m: Classifier.predict() missing 1 required positional argument: 'text'"
     ]
    }
   ],
   "source": [
    "model_sentiment.sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb340aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "189d0dc8866ae7c5243aefd5f9406ad445cf891fd6327591c18ad9e9bef8b20d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
