{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "877b7581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd         \n",
    "# import matplotlib.pyplot as plt\n",
    "from utilities import  create_bank_col, clean_tweet\n",
    "#Reading data and models\n",
    "import glob               \n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba723ff5",
   "metadata": {},
   "source": [
    "## Load in Twitter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35c13a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20313/1788197953.py:17: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# # Read the path\n",
    "# dir_datasets = os.getenv(\"DATASETS_PATH\")\n",
    "# directory = f\"{dir_datasets}/tweets_of_the_top_5_banks_in_SA/\"\n",
    "\n",
    "# # Use os.listdir() to get a list of all files in the directory\n",
    "# files = os.listdir(directory)\n",
    "\n",
    "# # Use a list comprehension to filter out only CSV files\n",
    "# csv_files = [file for file in files if file.endswith(\".csv\")]\n",
    "\n",
    "# # Initialize an empty list to store the dataframes\n",
    "# df_list = []\n",
    "\n",
    "# # Iterate over the CSV files and read them into pandas dataframes\n",
    "# for file in csv_files:\n",
    "#     file_path = os.path.join(directory, file)\n",
    "#     df = pd.read_csv(file_path)\n",
    "#     df_list.append(df)\n",
    "\n",
    "# # Concatenate the dataframes\n",
    "# tweets_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994d8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_parquet(\"tweets_from_2019-01-01_to_2019-01-02.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20d41a",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "527c1043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet_Id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Username</th>\n",
       "      <th>Reply_Count</th>\n",
       "      <th>Retweet_Count</th>\n",
       "      <th>Like_Count</th>\n",
       "      <th>Bank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 23:32:42+00:00</td>\n",
       "      <td>1080245458730184704</td>\n",
       "      <td>@SlowbucksAce Trippin ü§¶üèΩ‚Äç‚ôÇÔ∏è gotta give it to g...</td>\n",
       "      <td>fnb_justo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>fnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 22:36:31+00:00</td>\n",
       "      <td>1080231323552411650</td>\n",
       "      <td>Fake news or nah, I needed to see that SMS fro...</td>\n",
       "      <td>BangDulamo_ZA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 22:29:20+00:00</td>\n",
       "      <td>1080229514712678400</td>\n",
       "      <td>Them ‚ìÇÔ∏è's coming in I let 'em stack up üí∞ Don't...</td>\n",
       "      <td>fnb_justo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>fnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 21:55:39+00:00</td>\n",
       "      <td>1080221037395169280</td>\n",
       "      <td>FNB is so annoying with their unauthorized deb...</td>\n",
       "      <td>babyLangah</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fnb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 21:38:11+00:00</td>\n",
       "      <td>1080216641684819968</td>\n",
       "      <td>@hothaata Forget the critics let's start 2019 ...</td>\n",
       "      <td>NavasExpert</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fnb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime             Tweet_Id  \\\n",
       "0 2019-01-01 23:32:42+00:00  1080245458730184704   \n",
       "1 2019-01-01 22:36:31+00:00  1080231323552411650   \n",
       "2 2019-01-01 22:29:20+00:00  1080229514712678400   \n",
       "3 2019-01-01 21:55:39+00:00  1080221037395169280   \n",
       "4 2019-01-01 21:38:11+00:00  1080216641684819968   \n",
       "\n",
       "                                               Tweet       Username  \\\n",
       "0  @SlowbucksAce Trippin ü§¶üèΩ‚Äç‚ôÇÔ∏è gotta give it to g...      fnb_justo   \n",
       "1  Fake news or nah, I needed to see that SMS fro...  BangDulamo_ZA   \n",
       "2  Them ‚ìÇÔ∏è's coming in I let 'em stack up üí∞ Don't...      fnb_justo   \n",
       "3  FNB is so annoying with their unauthorized deb...     babyLangah   \n",
       "4  @hothaata Forget the critics let's start 2019 ...    NavasExpert   \n",
       "\n",
       "   Reply_Count  Retweet_Count  Like_Count Bank  \n",
       "0            0              0           3  fnb  \n",
       "1            0              0           0  fnb  \n",
       "2            0              1          11  fnb  \n",
       "3            0              0           0  fnb  \n",
       "4            0              0           0  fnb  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top records of dataset\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e39bd3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Datetime', 'Tweet_Id', 'Tweet', 'Username', 'Reply_Count',\n",
       "       'Retweet_Count', 'Like_Count', 'Bank'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns and features in data\n",
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52a83dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data is 405\n"
     ]
    }
   ],
   "source": [
    "# Length of dataset\n",
    "print('Length of data is', len(tweets_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46600819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 405 entries, 0 to 39\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype              \n",
      "---  ------         --------------  -----              \n",
      " 0   Datetime       405 non-null    datetime64[ns, UTC]\n",
      " 1   Tweet_Id       405 non-null    int64              \n",
      " 2   Tweet          405 non-null    string             \n",
      " 3   Username       405 non-null    string             \n",
      " 4   Reply_Count    405 non-null    int64              \n",
      " 5   Retweet_Count  405 non-null    int64              \n",
      " 6   Like_Count     405 non-null    int64              \n",
      " 7   Bank           405 non-null    string             \n",
      "dtypes: datetime64[ns, UTC](1), int64(4), string(3)\n",
      "memory usage: 28.5 KB\n"
     ]
    }
   ],
   "source": [
    "# Dataset information\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e40c5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null values: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for Null values\n",
    "print(f'Number of Null values: {np.sum(tweets_df.isnull().any(axis=1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c96adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_tweets, hashtags = clean_tweet(tweets_df['base_tweet'])\n",
    "# # Add the cleaned tweets and hashtags columns to the dataframe\n",
    "# tweets_df['clean_tweet'] = cleaned_tweets\n",
    "# tweets_df['hashtags'] = hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c3255c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (5) does not match length of index (1085729)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20313/259640621.py\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mcleaned_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Add the cleaned tweets and hashtags columns to the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtweets_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_tweet'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned_tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hashtags'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3976\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3977\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3978\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4170\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4171\u001b[0m         \"\"\"\n\u001b[0;32m-> 4172\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4174\u001b[0m         if (\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4911\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4912\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4913\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \"\"\"\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (5) does not match length of index (1085729)"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import emoji\n",
    "\n",
    "def translate_emoji(tweet):\n",
    "    if tweet == None or tweet == \"\":\n",
    "      tweet = tweet\n",
    "    else:\n",
    "      tweet = emoji.demojize(tweet).replace(\":\", \"\").replace(\"_\", \" \")\n",
    "    return tweet\n",
    "\n",
    "def remove_email(tweet):\n",
    "    email = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    return email.sub(r'',tweet)\n",
    "     \n",
    "def clean_tweet(tweets):\n",
    "    cleaned_tweets = []\n",
    "    hashtags = []\n",
    "    for tweet in tweets:\n",
    "        \n",
    "        # Remove mentions\n",
    "        tweet = re.sub(r'@\\w+', '', tweet)\n",
    "        \n",
    "        # Remove links\n",
    "        tweet = re.sub(r'http\\S+', '', tweet)\n",
    "        tweet = re.sub(r'www\\S+', '', tweet)\n",
    "        tweet = re.sub(r'bit.ly/\\S+', '', tweet) # remove bitly links\n",
    "        tweet = tweet.strip('[link]') # remove [links]\n",
    "        \n",
    "        # Remove email address\n",
    "        tweet = remove_email(tweet)\n",
    "        \n",
    "        # Translate emojis\n",
    "        tweet = translate_emoji(tweet)\n",
    "        \n",
    "        # Capture hashtags\n",
    "        hashtag_list = re.findall(r'#\\w+', tweet)\n",
    "        if len(hashtag_list) == 0:\n",
    "            hashtag_list = []\n",
    "            \n",
    "        hashtags.append(hashtag_list[1:])\n",
    "        \n",
    "        # Remove hashtags\n",
    "        tweet = re.sub(r\"#(\\w+)\", '', tweet)\n",
    "        \n",
    "        # Remove &amp\n",
    "        tweet = re.sub(r'&amp ', '', tweet)\n",
    "        \n",
    "        # Remove special characters\n",
    "        tweet = re.sub('([_]+)', \"\", tweet)\n",
    "        \n",
    "        # remove any unnecessary spaces\n",
    "        tweet = \" \".join(tweet.split())\n",
    "        \n",
    "        tweet = \"\".join(i for i in tweet if ord(i)<128)\n",
    "        \n",
    "        cleaned_tweets.append(tweet)\n",
    "    return cleaned_tweets, hashtags\n",
    "\n",
    "cleaned_tweets, hashtags = clean_tweet(tweets_df['base_tweet'].head(5))\n",
    "# Add the cleaned tweets and hashtags columns to the dataframe\n",
    "tweets_df['clean_tweet'] = cleaned_tweets\n",
    "tweets_df['hashtags'] = hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ae054",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[['base_tweet', 'cleaned_tweet', 'clean_tweet']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e0819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "3783e187a3956093a2d91726783b18164bbef240ac0a90eac75ec59d8f0bbb5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
