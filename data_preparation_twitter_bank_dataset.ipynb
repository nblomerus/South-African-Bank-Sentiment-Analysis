{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "877b7581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd         \n",
    "import matplotlib.pyplot as plt\n",
    "from utilities import  create_bank_col, clean_tweet\n",
    "#Reading data and models\n",
    "import glob               \n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba723ff5",
   "metadata": {},
   "source": [
    "## Load in Twitter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35c13a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20313/1788197953.py:17: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Read the path\n",
    "dir_datasets = os.getenv(\"DATASETS_PATH\")\n",
    "directory = f\"{dir_datasets}/tweets_of_the_top_5_banks_in_SA/\"\n",
    "\n",
    "# Use os.listdir() to get a list of all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Use a list comprehension to filter out only CSV files\n",
    "csv_files = [file for file in files if file.endswith(\".csv\")]\n",
    "\n",
    "# Initialize an empty list to store the dataframes\n",
    "df_list = []\n",
    "\n",
    "# Iterate over the CSV files and read them into pandas dataframes\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate the dataframes\n",
    "tweets_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "994d8be7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'twitter_data_2019-01-01_to_2019-01-02.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36006/2325077607.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"twitter_data_2019-01-01_to_2019-01-02.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'twitter_data_2019-01-01_to_2019-01-02.csv'"
     ]
    }
   ],
   "source": [
    "tweets_df = pd.read_csv(\"twitter_data_2019-01-01_to_2019-01-02.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f20d41a",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527c1043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>timezone</th>\n",
       "      <th>place</th>\n",
       "      <th>base_tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>language</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.358170e+18</td>\n",
       "      <td>1.358170e+18</td>\n",
       "      <td>1.612650e+12</td>\n",
       "      <td>2021/02/06 21:42</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@magefalco Let me know when you would like to ...</td>\n",
       "      <td>let me know when you would like to play agains...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'magefalco', 'name': 'PHNM | ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.358170e+18</td>\n",
       "      <td>1.358030e+18</td>\n",
       "      <td>1.612650e+12</td>\n",
       "      <td>2021/02/06 21:40</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Thabiso_TK Happy birthday to the handsome msu...</td>\n",
       "      <td>happy birthday to the handsome msushwana may h...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'Thabiso_TK', 'name': 'Thabis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.358170e+18</td>\n",
       "      <td>1.358170e+18</td>\n",
       "      <td>1.612650e+12</td>\n",
       "      <td>2021/02/06 21:40</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@SbuMasang JZ will give us Nedbank Cup.  And n...</td>\n",
       "      <td>jz will give us nedbank cup  and next season t...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'SbuMasang', 'name': 'Masango...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.358170e+18</td>\n",
       "      <td>1.358170e+18</td>\n",
       "      <td>1.612650e+12</td>\n",
       "      <td>2021/02/06 21:31</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This is result of SA Nedbank cup   â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”...</td>\n",
       "      <td>this is result of sa nedbank cup     february ...</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.358160e+18</td>\n",
       "      <td>1.358090e+18</td>\n",
       "      <td>1.612650e+12</td>\n",
       "      <td>2021/02/06 21:14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@Radebe_merci Invest bank &amp;amp; Absa</td>\n",
       "      <td>invest bank amp absa</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'Radebe_merci', 'name': 'ðŸŽ€Str...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            id  conversation_id    created_at              date  \\\n",
       "0           0  1.358170e+18     1.358170e+18  1.612650e+12  2021/02/06 21:42   \n",
       "1           1  1.358170e+18     1.358030e+18  1.612650e+12  2021/02/06 21:40   \n",
       "2           2  1.358170e+18     1.358170e+18  1.612650e+12  2021/02/06 21:40   \n",
       "3           3  1.358170e+18     1.358170e+18  1.612650e+12  2021/02/06 21:31   \n",
       "4           4  1.358160e+18     1.358090e+18  1.612650e+12  2021/02/06 21:14   \n",
       "\n",
       "   timezone place                                         base_tweet  \\\n",
       "0         0   NaN  @magefalco Let me know when you would like to ...   \n",
       "1         0   NaN  @Thabiso_TK Happy birthday to the handsome msu...   \n",
       "2         0   NaN  @SbuMasang JZ will give us Nedbank Cup.  And n...   \n",
       "3         0   NaN  This is result of SA Nedbank cup   â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”...   \n",
       "4         0   NaN               @Radebe_merci Invest bank &amp; Absa   \n",
       "\n",
       "                                       cleaned_tweet language  ... geo source  \\\n",
       "0  let me know when you would like to play agains...       en  ... NaN    NaN   \n",
       "1  happy birthday to the handsome msushwana may h...       en  ... NaN    NaN   \n",
       "2  jz will give us nedbank cup  and next season t...       en  ... NaN    NaN   \n",
       "3  this is result of sa nedbank cup     february ...       en  ... NaN    NaN   \n",
       "4                               invest bank amp absa       en  ... NaN    NaN   \n",
       "\n",
       "   user_rt_id  user_rt retweet_id  \\\n",
       "0         NaN      NaN        NaN   \n",
       "1         NaN      NaN        NaN   \n",
       "2         NaN      NaN        NaN   \n",
       "3         NaN      NaN        NaN   \n",
       "4         NaN      NaN        NaN   \n",
       "\n",
       "                                            reply_to  retweet_date  translate  \\\n",
       "0  [{'screen_name': 'magefalco', 'name': 'PHNM | ...           NaN        NaN   \n",
       "1  [{'screen_name': 'Thabiso_TK', 'name': 'Thabis...           NaN        NaN   \n",
       "2  [{'screen_name': 'SbuMasang', 'name': 'Masango...           NaN        NaN   \n",
       "3                                                 []           NaN        NaN   \n",
       "4  [{'screen_name': 'Radebe_merci', 'name': 'ðŸŽ€Str...           NaN        NaN   \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0       NaN        NaN  \n",
       "1       NaN        NaN  \n",
       "2       NaN        NaN  \n",
       "3       NaN        NaN  \n",
       "4       NaN        NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top records of dataset\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39bd3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'id', 'conversation_id', 'created_at', 'date', 'timezone',\n",
       "       'place', 'base_tweet', 'cleaned_tweet', 'language', 'hashtags',\n",
       "       'cashtags', 'user_id', 'user_id_str', 'username', 'name', 'day', 'hour',\n",
       "       'link', 'urls', 'photos', 'video', 'thumbnail', 'retweet', 'nlikes',\n",
       "       'nreplies', 'nretweets', 'quote_url', 'search', 'near', 'geo', 'source',\n",
       "       'user_rt_id', 'user_rt', 'retweet_id', 'reply_to', 'retweet_date',\n",
       "       'translate', 'trans_src', 'trans_dest'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns and features in data\n",
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a83dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data is 1085729\n"
     ]
    }
   ],
   "source": [
    "# Length of dataset\n",
    "print('Length of data is', len(tweets_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46600819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1085729 entries, 0 to 376539\n",
      "Data columns (total 40 columns):\n",
      " #   Column           Non-Null Count    Dtype  \n",
      "---  ------           --------------    -----  \n",
      " 0   Unnamed: 0       1085729 non-null  int64  \n",
      " 1   id               1085729 non-null  float64\n",
      " 2   conversation_id  1085729 non-null  float64\n",
      " 3   created_at       1085729 non-null  float64\n",
      " 4   date             1085729 non-null  object \n",
      " 5   timezone         1085729 non-null  int64  \n",
      " 6   place            964 non-null      object \n",
      " 7   base_tweet       1085729 non-null  object \n",
      " 8   cleaned_tweet    1001735 non-null  object \n",
      " 9   language         1085729 non-null  object \n",
      " 10  hashtags         1085729 non-null  object \n",
      " 11  cashtags         1085729 non-null  object \n",
      " 12  user_id          1085729 non-null  float64\n",
      " 13  user_id_str      1085729 non-null  float64\n",
      " 14  username         1085729 non-null  object \n",
      " 15  name             1085687 non-null  object \n",
      " 16  day              1085729 non-null  int64  \n",
      " 17  hour             1085729 non-null  int64  \n",
      " 18  link             1085729 non-null  object \n",
      " 19  urls             1085729 non-null  object \n",
      " 20  photos           1085729 non-null  object \n",
      " 21  video            1085729 non-null  int64  \n",
      " 22  thumbnail        163141 non-null   object \n",
      " 23  retweet          1085729 non-null  bool   \n",
      " 24  nlikes           1085729 non-null  int64  \n",
      " 25  nreplies         1085729 non-null  int64  \n",
      " 26  nretweets        1085729 non-null  int64  \n",
      " 27  quote_url        45733 non-null    object \n",
      " 28  search           1085729 non-null  object \n",
      " 29  near             0 non-null        float64\n",
      " 30  geo              0 non-null        float64\n",
      " 31  source           0 non-null        float64\n",
      " 32  user_rt_id       0 non-null        float64\n",
      " 33  user_rt          0 non-null        float64\n",
      " 34  retweet_id       0 non-null        float64\n",
      " 35  reply_to         1085729 non-null  object \n",
      " 36  retweet_date     0 non-null        float64\n",
      " 37  translate        0 non-null        float64\n",
      " 38  trans_src        0 non-null        float64\n",
      " 39  trans_dest       0 non-null        float64\n",
      "dtypes: bool(1), float64(15), int64(8), object(16)\n",
      "memory usage: 332.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Dataset information\n",
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e40c5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Null values: 376540\n"
     ]
    }
   ],
   "source": [
    "# Checking for Null values\n",
    "print(f'Number of Null values: {np.sum(df.isnull().any(axis=1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c96adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_tweets, hashtags = clean_tweet(tweets_df['base_tweet'])\n",
    "# # Add the cleaned tweets and hashtags columns to the dataframe\n",
    "# tweets_df['clean_tweet'] = cleaned_tweets\n",
    "# tweets_df['hashtags'] = hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c3255c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (5) does not match length of index (1085729)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20313/259640621.py\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mcleaned_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_tweet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'base_tweet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# Add the cleaned tweets and hashtags columns to the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtweets_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clean_tweet'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleaned_tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0mtweets_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hashtags'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashtags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3976\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3977\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3978\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4170\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4171\u001b[0m         \"\"\"\n\u001b[0;32m-> 4172\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4174\u001b[0m         if (\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4911\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4912\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4913\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.10/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \"\"\"\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (5) does not match length of index (1085729)"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import emoji\n",
    "\n",
    "def translate_emoji(tweet):\n",
    "    if tweet == None or tweet == \"\":\n",
    "      tweet = tweet\n",
    "    else:\n",
    "      tweet = emoji.demojize(tweet).replace(\":\", \"\").replace(\"_\", \" \")\n",
    "    return tweet\n",
    "\n",
    "def remove_email(tweet):\n",
    "    email = re.compile(r'[\\w\\.-]+@[\\w\\.-]+')\n",
    "    return email.sub(r'',tweet)\n",
    "     \n",
    "def clean_tweet(tweets):\n",
    "    cleaned_tweets = []\n",
    "    hashtags = []\n",
    "    for tweet in tweets:\n",
    "        \n",
    "        # Remove mentions\n",
    "        tweet = re.sub(r'@\\w+', '', tweet)\n",
    "        \n",
    "        # Remove links\n",
    "        tweet = re.sub(r'http\\S+', '', tweet)\n",
    "        tweet = re.sub(r'www\\S+', '', tweet)\n",
    "        tweet = re.sub(r'bit.ly/\\S+', '', tweet) # remove bitly links\n",
    "        tweet = tweet.strip('[link]') # remove [links]\n",
    "        \n",
    "        # Remove email address\n",
    "        tweet = remove_email(tweet)\n",
    "        \n",
    "        # Translate emojis\n",
    "        tweet = translate_emoji(tweet)\n",
    "        \n",
    "        # Capture hashtags\n",
    "        hashtag_list = re.findall(r'#\\w+', tweet)\n",
    "        if len(hashtag_list) == 0:\n",
    "            hashtag_list = []\n",
    "            \n",
    "        hashtags.append(hashtag_list[1:])\n",
    "        \n",
    "        # Remove hashtags\n",
    "        tweet = re.sub(r\"#(\\w+)\", '', tweet)\n",
    "        \n",
    "        # Remove &amp\n",
    "        tweet = re.sub(r'&amp ', '', tweet)\n",
    "        \n",
    "        # Remove special characters\n",
    "        tweet = re.sub('([_]+)', \"\", tweet)\n",
    "        \n",
    "        # remove any unnecessary spaces\n",
    "        tweet = \" \".join(tweet.split())\n",
    "        \n",
    "        tweet = \"\".join(i for i in tweet if ord(i)<128)\n",
    "        \n",
    "        cleaned_tweets.append(tweet)\n",
    "    return cleaned_tweets, hashtags\n",
    "\n",
    "cleaned_tweets, hashtags = clean_tweet(tweets_df['base_tweet'].head(5))\n",
    "# Add the cleaned tweets and hashtags columns to the dataframe\n",
    "tweets_df['clean_tweet'] = cleaned_tweets\n",
    "tweets_df['hashtags'] = hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ae054",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[['base_tweet', 'cleaned_tweet', 'clean_tweet']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7e0819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
